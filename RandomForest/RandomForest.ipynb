{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self, left=None, right=None, feature=None, split_value=None, data=None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.feature = feature\n",
    "        self.split_value = split_value\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "\n",
    "    def __init__(self, min_values=10):\n",
    "        self.root = None\n",
    "        self.min_values = min_values\n",
    "\n",
    "    def entropy(self, y):\n",
    "        elements, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = [i / len(y) for i in counts]\n",
    "        entropy = np.sum([-i * np.log2(i) for i in probabilities])\n",
    "        return entropy\n",
    "\n",
    "    def information_gain(self, y, left_side, right_side):\n",
    "        parent_entropy = self.entropy(y)\n",
    "        average_child_entropy = len(left_side) / len(y) * self.entropy(y[left_side]) + len(right_side) / len(y) * self.entropy(y[right_side])\n",
    "        IG = parent_entropy - average_child_entropy\n",
    "        return IG\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_classes = len(np.unique(y))\n",
    "\n",
    "        # stopping conditions\n",
    "        if n_classes == 1 or X.shape[0] <= self.min_values:\n",
    "            leaf_node = lambda x: np.bincount(x).argmax()\n",
    "            return Node(data=leaf_node(y))\n",
    "\n",
    "        # search all data points to find the feature and split value with the highest information gain\n",
    "        features = [i for i in range(0, X.shape[1])]\n",
    "        best_feature, best_split_value, gain = 0, 0, 0\n",
    "        for feature in features:\n",
    "            X_column = X[:, feature]\n",
    "            split_values = np.unique(X_column)\n",
    "            for split_value in split_values:\n",
    "                left_side, right_side = self.binary_separation(X_column, split_value)\n",
    "                information_gain = self.information_gain(y, left_side, right_side)\n",
    "                if information_gain > gain:\n",
    "                    gain = information_gain\n",
    "                    best_feature = feature\n",
    "                    best_split_value = split_value\n",
    "\n",
    "        # grow tree recursively\n",
    "        left_side, right_side = self.binary_separation(X[:, best_feature], best_split_value)\n",
    "        left = self.fit(X[left_side, :], y[left_side])\n",
    "        right = self.fit(X[right_side, :], y[right_side])\n",
    "        self.root = Node(left, right, best_feature, best_split_value)\n",
    "        return self.root\n",
    "    \n",
    "    def binary_separation(self, X_column, split_value):\n",
    "        left_side = np.where(X_column <= split_value)\n",
    "        right_side = np.where(X_column > split_value)\n",
    "        return left_side[0], right_side[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        def predict_for(i, node):\n",
    "            if node.left is None and node.right is None:\n",
    "                return node.data\n",
    "            elif i[node.feature] <= node.split_value:\n",
    "                return predict_for(i, node.left)\n",
    "            else:\n",
    "                return predict_for(i, node.right)\n",
    "\n",
    "        return np.array([predict_for(i, self.root) for i in X])\n",
    "\n",
    "    def accuracy(self, y_true, y_prediction):\n",
    "        return np.sum(y_true == y_prediction) / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "\n",
    "    def __init__(self, n_trees = 50):\n",
    "        self.n_trees = n_trees\n",
    "\n",
    "    def bootstrap(self, X, y):\n",
    "        indexes = np.random.choice(len(X), len(X), replace=True)\n",
    "        return X[indexes, :], y[indexes]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = list()\n",
    "        tree = DecisionTreeClassifier()\n",
    "        for i in range(self.n_trees):\n",
    "            X_sample, y_sample = self.bootstrap(X, y)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees]).T\n",
    "        y_prediction = [np.bincount(p).argmax() for p in predictions]\n",
    "        return np.array(y_prediction)\n",
    "\n",
    "    def accuracy(self, y_true, y_prediction):\n",
    "        return np.sum(y_true == y_prediction) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate of Random Forest Implementation: 0.9300699300699301\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data = datasets.load_breast_cancer()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "    rf = RandomForest(20)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_prediction = rf.predict(X_test)\n",
    "    accuracy = rf.accuracy(y_test, y_prediction)\n",
    "    print(\"Accuracy rate of Random Forest Implementation:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
